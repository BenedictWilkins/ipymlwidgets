{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60ff11c08ba048b7b487542e7829d927",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ImageAnnotated(children=(Box(children=(HTML(value='\\n<style>\\n.image-overlay {\\n    position: absolute;\\n    t…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipymlwidgets import Image, ImageAnnotated\n",
    "import torch\n",
    "import ipywidgets as W\n",
    "size = (320,480)\n",
    "\n",
    "xy = torch.randint(size[0]-10, (1,2))\n",
    "boxes = torch.cat([xy, xy + 10, torch.zeros_like(xy[:, :1])], dim=-1).float()\n",
    "#image = Image(torch.rand(3,*size))\n",
    "image = ImageAnnotated(torch.rand((3,*size)), boxes=boxes)\n",
    "display(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6.0000,  7.0000, 16.0000, 17.0000,  0.0000],\n",
      "        [20.7000,  9.5000, 20.7000,  9.5000,  0.0000]])\n"
     ]
    }
   ],
   "source": [
    "print(image.boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ImageAnnotated.__init__() got an unexpected keyword argument 'display_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mipywidgets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mW\u001b[39;00m\n\u001b[1;32m      5\u001b[0m size \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m320\u001b[39m,\u001b[38;5;241m320\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mImageAnnotated\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrand\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisplay_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m selection_text \u001b[38;5;241m=\u001b[39m W\u001b[38;5;241m.\u001b[39mText(value\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,disabled\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,layout\u001b[38;5;241m=\u001b[39mW\u001b[38;5;241m.\u001b[39mLayout(width\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m100%\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mupdate_selection_text\u001b[39m(change):\n",
      "\u001b[0;31mTypeError\u001b[0m: ImageAnnotated.__init__() got an unexpected keyword argument 'display_size'"
     ]
    }
   ],
   "source": [
    "\n",
    "from ipymlwidgets import ImageAnnotated\n",
    "import torch\n",
    "import ipywidgets as W\n",
    "\n",
    "size = (320,320)\n",
    "image = ImageAnnotated(torch.rand((3,32,32)), display_size=size)\n",
    "selection_text = W.Text(value=\"\",disabled=True,layout=W.Layout(width=f'100%'))\n",
    "def update_selection_text(change):\n",
    "    selection_text.value = str(change[\"new\"])\n",
    "    \n",
    "label_text = W.Text(value=\"\", disabled=False, layout=W.Layout(width=f'100%'))\n",
    "\n",
    "image.observe(update_selection_text, \"selection\")\n",
    "\n",
    "xy = torch.randint(image.size[0]-10, (1,2))\n",
    "boxes = torch.cat([xy, xy + 10, torch.zeros_like(xy[:, :1])], dim=-1).float()\n",
    "image.boxes = boxes\n",
    "\n",
    "display(selection_text)\n",
    "display(image)\n",
    "display(label_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 9.0000, 18.0000, 19.0000, 28.0000,  0.0000],\n",
      "        [13.2000,  5.9000, 23.1000, 13.0000,  0.0000],\n",
      "        [ 4.3000,  5.6000,  4.3000,  5.6000,  0.0000]])\n",
      "tensor([[ 90., 180., 190., 280.,   0.],\n",
      "        [132.,  59., 231., 130.,   0.],\n",
      "        [ 43.,  56.,  95., 118.,   0.]])\n"
     ]
    }
   ],
   "source": [
    "print(image.boxes)\n",
    "print(image._overlay_box.boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[11., 19., 21., 29.]])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "143691eacf8c438487acf4ce43b77e02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ImageOCR(children=(Box(children=(HTML(value='\\n<style>\\n.overlay-image {\\n    position: absolute;\\n    top: 0;…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipymlwidgets.widgets.image_ocr import ImageOCR\n",
    "import torch\n",
    "\n",
    "size = (32,48)\n",
    "image = torch.rand((3,size[1],size[0]))\n",
    "x = torch.randint(size[0]-10, (1,1))\n",
    "y = torch.randint(size[1]-10, (1,1))\n",
    "boxes = torch.cat([x, y, x + 10, y + 10], dim=-1).float()\n",
    "print(boxes)\n",
    "\n",
    "image_ocr = ImageOCR(image, boxes=boxes, texts=[\"hello there\"])# display_size=(size[0]*10,size[0]*10))\n",
    "display(image_ocr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from traitlets import Int, dlink, link, HasTraits\n",
    "\n",
    "class A(HasTraits):\n",
    "    x = Int()\n",
    "\n",
    "\n",
    "class B(HasTraits):\n",
    "    x = Int()\n",
    "\n",
    "    def __init__(self, a: A):\n",
    "        self.a = a\n",
    "        dlink((self, \"x\"), (self.a, \"x\"), self.transform_ba)\n",
    "        dlink((self.a, \"x\"), (self, \"x\"), self.transform_ab)\n",
    "\n",
    "    def transform_ab(self, value):\n",
    "        return value + 7\n",
    "    \n",
    "    def transform_ba(self, value):\n",
    "        return value - 7\n",
    "\n",
    "\n",
    "a = A() \n",
    "b = B(a)\n",
    "\n",
    "print(a.x, b.x)\n",
    "\n",
    "a.x += 1\n",
    "\n",
    "print(a.x, b.x)\n",
    "\n",
    "b.x += 1\n",
    "\n",
    "print(a.x, b.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipymlwidgets.widgets.box_overlay import BoxOverlay\n",
    "import torch\n",
    "size = (320,60)\n",
    "x = torch.randint(size[0]-10, (1,1))\n",
    "y = torch.randint(size[1]-10, (1,1))\n",
    "boxes = torch.cat([x, y, x + 10, y + 10], dim=-1).float()\n",
    "\n",
    "overlay = BoxOverlay(boxes, overlay_size=size)\n",
    "display(overlay)\n",
    "\n",
    "#box.observe_mouse_click(print)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.empty(0)\n",
    "print(x.ndim, x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image.boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from ipymlwidgets.widgets import Image\n",
    "import torch\n",
    "\n",
    "image = Image(torch.rand((3,10,10)))\n",
    "display(image)\n",
    "image.observe_mouse_click(print)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipymlwidgets.widgets.image import Image\n",
    "import torch\n",
    "\n",
    "class OverlayContainer(widgets.Box):\n",
    "    \"\"\"A container that overlays multiple images using CSS.\"\"\"\n",
    "    \n",
    "    def __init__(self, width: int = 640, height: int = 480, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        # Add CSS for overlay positioning\n",
    "        self.add_class(\"overlay-container\")\n",
    "        \n",
    "        # Set up layout\n",
    "        self.layout = widgets.Layout(\n",
    "            width=f\"{width}px\",\n",
    "            height=f\"{height}px\"\n",
    "        )\n",
    "\n",
    "# Add CSS to the page\n",
    "css = \"\"\"\n",
    "<style>\n",
    ".overlay-image {\n",
    "    position: absolute;\n",
    "    top: 0;\n",
    "    left: 0;\n",
    "}\n",
    "</style>\n",
    "\"\"\"\n",
    "\n",
    "size = (640,640 )\n",
    "# Create container and images\n",
    "container = OverlayContainer(width=size[0], height=size[1])\n",
    "\n",
    "image = torch.randn((3,10,10))\n",
    "\n",
    "image1 = Image(image=torch.ones((3,10,10)) * 200, layers=1)\n",
    "image2 = Image(image=torch.randn((4,200,200)), layers=1)\n",
    "image1.add_class(\"overlay-image\")\n",
    "image2.add_class(\"overlay-image\")\n",
    "\n",
    "container.children = [widgets.HTML(css), image1, image2]\n",
    "\n",
    "# Display\n",
    "display(container)\n",
    "\n",
    "print(image1.layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipymlwidgets.widgets.image import Image\n",
    "import torch\n",
    "\n",
    "OVERLAY_CSS = \"\"\"\n",
    "<style>\n",
    ".overlay-image {\n",
    "    position: absolute;\n",
    "    top: 0;\n",
    "    left: 0;\n",
    "}\n",
    "</style>\n",
    "\"\"\"\n",
    "class ImageAnnotated(widgets.Box):\n",
    "    \n",
    "    def __init__(self, image, overlay, size : tuple[int,int] = (320,320)):\n",
    "        self._image_canvas = Image(image)\n",
    "        self._image_canvas.add_class(\"overlay-image\")\n",
    "        self._overlay_canvas = Image(overlay)\n",
    "        self._overlay_canvas.add_class(\"overlay-image\")\n",
    "        size = (f\"{size[0]}px\", f\"{size[1]}px\") if size is not None else (\"100%\", \"auto\")\n",
    "        layout = widgets.Layout(\n",
    "            width=size[0],\n",
    "            height=size[1],\n",
    "        )\n",
    "        super().__init__([widgets.HTML(OVERLAY_CSS), self._image_canvas, self._overlay_canvas], layout=layout)\n",
    "\n",
    "\n",
    "image = torch.zeros((3,10,10))\n",
    "image[0,:,:] = torch.rand((10,10))\n",
    "\n",
    "overlay = torch.zeros((4,50,60)) \n",
    "overlay[-1] = torch.rand((50,60))\n",
    "\n",
    "#overlay = torch.zeros((4,50,50))\n",
    "\n",
    "# Create container and images\n",
    "image = ImageAnnotated(\n",
    "    image,\n",
    "    overlay,\n",
    ")\n",
    "\n",
    "\n",
    "image._overlay_canvas.observe_mouse_click(print)\n",
    "image._image_canvas.observe_mouse_click(print)\n",
    "\n",
    "display(image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
